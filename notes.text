a 1-bit computer design:
http://tinymicros.com/mediawiki/images/e/ec/MC14500B_Handbook.pdf

a programmable state machine that's economical with logic:
http://laughtonelectronics.com/Arcana/One-bit%20computer/One-bit%20computer.html
see also http://en.wikipedia.org/wiki/Motorola_MC14500B

Could the tictactoe circuit be simpler using state?

another angle on what i'm trying to do here: when you try to break
down meanings in everyday life, like a philosopher or semanticist, you
never really get to the bottom of things. dictionary definitions are
circular and anyway superficial, etc. the surprising thing in
computation is, when we practice analysis and synthesis we *get
somewhere*: crisp constructions small enough for an individual to
wholly grasp can describe worlds.

http://www.cs.uni.edu/~wallingf/blog/archives/monthly/2012-12.html#e2012-12-12T16_18_28.htm
"be a driver, not a passenger"

http://jsshaper.org/ might be a more useful JS parser


"Almost all lectures, even those by brilliant researchers, were
dreary. (A shining exception by Robin Hanson.) They suffered from a
lack of stories and a lack of emotion."
http://blog.sethroberts.net/2012/12/09/online-teaching-versus-what/

http://blog.notdot.net/2012/10/Build-your-own-FPGA

coffeescript docs -- 2 columns. makes sense on-screen.

take a look at myhdl: http://www.myhdl.org/doku.php/cookbook:intro

on homunculi: try riffing on mccarthy's "ascribing mental qualities to
machines". (we want to dispel them *temporarily*. they're useful.)
http://gigasquidsoftware.com/wordpress/?p=477

can we somehow incorporate btilly's strategy to teach linear algebra,
with spaced review, etc.?
http://news.ycombinator.com/item?id=4701321
http://calnewport.com/blog/2012/10/26/mastering-linear-algebra-in-10-days-astounding-experiments-in-ultra-learning/
It's worth presenting these ideas as advice to the reader in how to 
get the most out of it, anyway.

Eliezer, "The Nature of Logic"

exercise: superopt from superbench

after there's something to write about, write about this for http://push.cwcon.org/

on the interaction interface: compute values one at a time, filling in
placeholders (in case of a long-running computation)

there really should be some stuff explicitly about self-reference and
quining and self-replication in life, etc.

 S. Ishihara, S. Minato. Manipulation of Regular Expressions Under
Length Constraints Using Zero-Suppressed BDDs.  Proc. of ASP-DAC .95,
pp. 391-396.


  I particularly like the 'instructing homunculi' vs 'inanimate
  causality' distinction. Do you think there might be (after some
  training) an intermediate a 'functional' mindset, where the
  programmer understands the code in terms of definitional rules which
  are semantic like instructions, but a bit lifeless like rods or
  gears?

  Sometimes it's necessary to break out of a functional mindset into
  an inanimate causality mindset in order to go down below the
  linguistic abstractions and talk about, for example, space or time
  concerns.

problem (vague statement): given a logic puzzle, generate a verbal
argument compelling assent to its solution.

yet another small computer design, includes detailed tutorial pdf:
http://cpuville.com/

http://cosmicos.sourceforge.net/
http://people.csail.mit.edu/paulfitz/cosmicos.shtml

http://www.cs.uni.edu/~wallingf/blog/archives/monthly/2013-04.html#e2013-04-20T10_25_41.htm
"Woz described how, after seeing Pong in a video arcade, he went home
and built his own Pong game out of twenty-eight $1 chips." Also
Hexapawn: better example than tic-tac-toe?

http://arxiv.org/abs/1009.1720

http://blog.notdot.net/2012/10/Build-your-own-FPGA
http://dangerousprototypes.com/2012/11/09/open-7400-logic-competition-winners-2012/

when/if you introduce reversibility, do it with the Fredkin gate: it's
just a tweak to the if-then-else we're using.

do Karnaugh maps make sense if you're thinking in terms of
if-then-else instead of sum-of-product?

what does resolution look like if you generalize from and/or to
min/max? or use only if-then-else?

C.S. Peirce (1887), "Logical Machines"
Peirce also had the idea of Shannon's switching circuits as boolean
algebra, in a letter to Marquand of 1886.
http://libweb5.princeton.edu/visual_materials/pulc/pulc_v_45_n_3.pdf


From: Dave Long <dave.long@bluewin.ch>
Date: Fri, 28 Nov 2014 10:09:23 +0100

> shouldn't we also calculate sequential circuits, using
> Kleene algebra?

cf Möller, "Algebraic Structures for Program Calculation" (his final
example is calculation of a systolic convolution)

Very helpful for me, as Möller actually proves several things in this
paper that I had been using as "working assumptions".  (and his
bibliography is somewhat of a "transitive closure", in that he not
only cites his direct predecessors, but also foundational material
back in the 1950's and 60's)

Unfortunately he doesn't seem to have any of his papers available on
his home page; I wound up reading this one through a friendlier-than-
usual Google Books image.

-Dave
